<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CNN,MNIST," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="卷积神经网络卷积神经网络 (Convolutional Neural Network, CNN)，是一种专门用来处理具有网格结构数据的神经网络。例如时间序列数据(时间轴上的一维网格)和图像数据(二维的像素网格)。 CNN作为一个深度学习架构被提出的最初诉求，是降低对图像数据预处理的要求，以及避免复杂的特征工程。CNN可以直接使用图像作为输入，减少了许多特征提取的手续。CNN的最大特点在于卷积的权值">
<meta name="keywords" content="CNN,MNIST">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络(Convolutional Neural Network）">
<meta property="og:url" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional Neural Network)/index.html">
<meta property="og:site_name" content="Zejian&#39;s Blog">
<meta property="og:description" content="卷积神经网络卷积神经网络 (Convolutional Neural Network, CNN)，是一种专门用来处理具有网格结构数据的神经网络。例如时间序列数据(时间轴上的一维网格)和图像数据(二维的像素网格)。 CNN作为一个深度学习架构被提出的最初诉求，是降低对图像数据预处理的要求，以及避免复杂的特征工程。CNN可以直接使用图像作为输入，减少了许多特征提取的手续。CNN的最大特点在于卷积的权值">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">
<meta property="og:updated_time" content="2017-11-01T09:09:06.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="卷积神经网络(Convolutional Neural Network）">
<meta name="twitter:description" content="卷积神经网络卷积神经网络 (Convolutional Neural Network, CNN)，是一种专门用来处理具有网格结构数据的神经网络。例如时间序列数据(时间轴上的一维网格)和图像数据(二维的像素网格)。 CNN作为一个深度学习架构被提出的最初诉求，是降低对图像数据预处理的要求，以及避免复杂的特征工程。CNN可以直接使用图像作为输入，减少了许多特征提取的手续。CNN的最大特点在于卷积的权值">
<meta name="twitter:image" content="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional%20Neural%20Network)/2017-10-19-卷积神经网络(Convolutional%20Neural%20Network">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional Neural Network)/"/>





  <title>卷积神经网络(Convolutional Neural Network） | Zejian's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zejian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">这么好的故事，你可别演砸了。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lizejian.github.io.com/2017/10/19/卷积神经网络(Convolutional Neural Network)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zejian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zejian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">卷积神经网络(Convolutional Neural Network）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T22:06:16+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络 (Convolutional Neural Network, CNN)，是一种专门用来处理具有网格结构数据的神经网络。例如时间序列数据(时间轴上的一维网格)和图像数据(二维的像素网格)。</p>
<p>CNN作为一个深度学习架构被提出的最初诉求，是降低对图像数据预处理的要求，以及避免复杂的特征工程。CNN可以直接使用图像作为输入，减少了许多特征提取的手续。CNN的最大特点在于卷积的权值共享结构，大幅度减少神经网络的参数，同时防止了过拟合。</p>
<h1 id="卷积神经网络结构）"><a href="#卷积神经网络结构）" class="headerlink" title="卷积神经网络结构）"></a>卷积神经网络结构）</h1><p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-2017101621075175.png)</p>
<p>一般来说，卷积神经网络主要由以下结构组成:</p>
<h2 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h2><p>输入层是整个神经网络的输入，一般为图片的像素矩阵(一般为三维矩阵，即像素x像素x通道)</p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层的作用是从输入层中抽象出更高的特征。一般流程如下：</p>
<ol>
<li><p>图像通过<strong>多个不同的卷积核</strong>滤波，并添加偏置(bias)，提取局部特征，每一个卷积核会映射出一个新的2D图像。</p>
</li>
<li><p>将前面卷积核的滤波输出结果，进行非线性的激活函数处理。</p>
</li>
<li><p>对激活函数的结构再进行池化操作(降采样），目前一般使用最大池化，保留最大特征，提示模型的畸变容忍能力。</p>
</li>
</ol>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>图像处理中的卷积计算，依赖于卷积核Kernel，而卷积核就是一个滤波器，卷积核与输入信号做加权叠加得到输出。</p>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-20171016211502468.png)<br><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/20170719111641148.gif)</p>
<p>卷积参数（以上图为例）</p>
<ul>
<li>输入尺寸4x4</li>
<li>卷积核尺寸3x3</li>
<li>输出尺寸2x2</li>
<li>移动步长（stride）1</li>
</ul>
<p>可以发现，只要卷积核的尺寸不是1x1,那么输出尺寸必定会小于输入尺寸大小。而在实际图片处理过程中，很多时候需要保持图像的大小不变。为了保持输入和输出尺寸一致，同时也有卷积的效果，我们对输入图片的外圈做填充操作。</p>
<p>因此，引入新的参数padding，即在输入的外圈补零的圈数(数字零对卷积贡献为零,不会产生额外的偏差)。</p>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/20170719114528262.gif)</p>
<p>这里给出输入尺寸、输出尺寸、滤波器尺寸、stride和padding的关系:</p>
<p>输入图片的尺寸大小W1 x H1</p>
<p>卷积核(又称滤波器，以下都称滤波器)的大小F x F</p>
<p>stride：S padding:P</p>
<p>输出图片的尺寸大小W2 x H2</p>
<p>$W2 = (W1-F+2P)/S + 1$</p>
<p>$H2 = (H1-F+2P)/S + 1$</p>
<h3 id="权值共享"><a href="#权值共享" class="headerlink" title="权值共享"></a>权值共享</h3><p>每一个卷积层中使用的过滤器参数是相同的，这就是卷积核的权值共享。</p>
<ul>
<li><p>从直观上理解，共享卷积核可以使得图像上的内容不受位置的影响，这提高了模型对平移的容忍性，这大大的提高了模型提取特征的能力。</p>
</li>
<li><p>从网络结构上来说，共享每一个卷积层的卷积核，可以大大减少网络的参数，这不仅可以降低计算的复杂度，而且还能减少因为连接过多导致的严重过拟合，从而提高模型的泛化能力。</p>
</li>
</ul>
<p>权值共享与传统的全连接的区别如下图：</p>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-20171016214052344.png)</p>
<h3 id="多卷积核"><a href="#多卷积核" class="headerlink" title="多卷积核"></a>多卷积核</h3><p>在每一个卷积层中，会使用多个卷积核运算。这是因为每一个卷积核滤波得到的图像就是一类特征的映射，使用多个卷积核，就能提供多个方向上的图像特征，可以从图像中抽象出有效而丰富的高阶特征。</p>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-20171016214315791.png)</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层可以非常有效地缩小图片的尺寸，减少最后全连接层的参数，保留最显著的特征，提升模型的畸变容忍能力，防止过拟合。</p>
<p>池化层前向传播过程类似于卷积层，是通过移动一个类似滤波器的结构完成的。与卷积层不同的是，池化层的滤波器计算不是加权求和，而且求区域内的极大值或者平均值。</p>
<ul>
<li>最大池化层(max pooling)，最常使用，计算图像区域内最大值，提取纹理效果较好。</li>
</ul>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-20171016214730544.png)</p>
<ul>
<li>平均池化层(mean pooling)，计算图像区域的平均值，保留背景更好。</li>
</ul>
<p><img src="2017-10-19-卷积神经网络(Convolutional Neural Network" alt="">/markdown-img-paste-20171016214806523.png)</p>
<ul>
<li>随机池化层(stochastic pooling)，介于两者之间，通过对像素点按照数值大小赋予概率，再按照概率进行亚采样。</li>
</ul>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>图像中被抽象成了信息含量更高的特征在经过神经网络完成后续分类等任务。</p>
<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><p>一般是使用softmax输出概率值或者分类结果。</p>
<h1 id="TensorFlow部署CNN"><a href="#TensorFlow部署CNN" class="headerlink" title="TensorFlow部署CNN"></a>TensorFlow部署CNN</h1><h2 id="卷积-1"><a href="#卷积-1" class="headerlink" title="卷积"></a>卷积</h2><p>通道混合处理的任意滤波器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.nn.conv2d(x, W, strides, padding)</div></pre></td></tr></table></figure></p>
<p>strides = [batch, width, height, channels]</p>
<ul>
<li>batch = 1表示样本一个一个遍历</li>
<li>width height = 1表示移动的步长</li>
<li>channels = 1表示通道一个一个滑动</li>
</ul>
<p>padding = ‘SAME’,’VALID’</p>
<ul>
<li>‘SAME’ 输入输出尺寸相同</li>
<li>‘VALID’ (w-f)/k + 1</li>
</ul>
<h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.nn.max_pool(x, ksize, strides, padding)</div></pre></td></tr></table></figure>
<p>ksize = [1, height, width, 1]</p>
<ul>
<li>batch = 1表示不在样本上做池化</li>
<li>width height表示池化窗口大小</li>
<li>channels = 1表示不在通道上做池化</li>
</ul>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tf.nn.relu(x)</div><div class="line">tf.nn.dropout(x, keep_prob)</div><div class="line">tf.nn.bias_add(x, b)</div><div class="line">tf.sigmoid(x)</div><div class="line">tf.tanh(x)</div></pre></td></tr></table></figure>
<h1 id="CNN-应用-MNIST"><a href="#CNN-应用-MNIST" class="headerlink" title="CNN 应用 MNIST"></a>CNN 应用 MNIST</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line"></div><div class="line">def initialize_weight(shape):</div><div class="line">	initial = tf.truncated_normal(shape, stddev = 0.1)</div><div class="line">	return tf.Variable(initial)</div><div class="line"></div><div class="line">def initialize_bias(shape):</div><div class="line">	initial = tf.constant(0.1, shape = shape)</div><div class="line">	return tf.Variable(initial)</div><div class="line"></div><div class="line">def conv2d(x, W):</div><div class="line">	return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = &apos;SAME&apos;)</div><div class="line"></div><div class="line">def max_pool_2x2(x):</div><div class="line">	return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = &apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line">#create CNN Model</div><div class="line">x = tf.placeholder(&apos;float&apos;, [None, 784])</div><div class="line">y = tf.placeholder(&apos;float&apos;, [None, 10])</div><div class="line">x_image = tf.reshape(x, [-1,28,28,1])#28x28x1</div><div class="line"></div><div class="line"># layer1:conv2d</div><div class="line">W1_conv = initialize_weight([5, 5, 1, 32])</div><div class="line">b1_conv = initialize_bias([32])</div><div class="line">h1_conv = tf.nn.relu(conv2d(x_image, W1_conv) + b1_conv)#28x28x1&gt;&gt;28x28x32</div><div class="line">h1_pool = max_pool_2x2(h1_conv)#28x28x32&gt;&gt;14x14x32</div><div class="line"></div><div class="line"># layer2:conv2d</div><div class="line">W2_conv = initialize_weight([5, 5, 32, 64])</div><div class="line">b2_conv = initialize_bias([64])</div><div class="line">h2_conv = tf.nn.relu(conv2d(h1_pool, W2_conv) + b2_conv)#14x14x32&gt;&gt;14x14x64</div><div class="line">h2_pool = max_pool_2x2(h2_conv)#14x14x64&gt;&gt;7x7x64</div><div class="line">h2_pool_flat = tf.reshape(h2_pool, [-1, 7*7*64])#7x7x64&gt;&gt;7*7*64</div><div class="line"></div><div class="line"># layer3:full connection</div><div class="line">W3_fc = initialize_weight([7*7*64, 1024])</div><div class="line">b3_fc = initialize_bias([1024])</div><div class="line">h3_fc = tf.nn.relu(tf.matmul(h2_pool_flat, W3_fc) + b3_fc)#7*7*64&gt;&gt;1024</div><div class="line"></div><div class="line"># drop out</div><div class="line">keep_prob = tf.placeholder(&apos;float&apos;)</div><div class="line">h3_fc_drop = tf.nn.dropout(h3_fc, keep_prob)</div><div class="line"></div><div class="line"># layer4: full connection</div><div class="line">W4_fc = initialize_weight([1024, 10])</div><div class="line">b4_fc = initialize_bias([10])</div><div class="line">y_conv = tf.nn.softmax(tf.matmul(h3_fc_drop, W4_fc) + b4_fc)</div><div class="line"></div><div class="line">cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &apos;float&apos;))</div><div class="line"></div><div class="line"># train model</div><div class="line">mnist = input_data.read_data_sets(&apos;MNIST_data/&apos;, one_hot = True)</div><div class="line">sess = tf.Session()</div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line">for i in range(20000):</div><div class="line">	batch = mnist.train.next_batch(50)</div><div class="line">	if i % 100 == 0:</div><div class="line">		train_accuracy = sess.run(accuracy, feed_dict = &#123;x: batch[0], y: batch[1], keep_prob: 1.0&#125;)</div><div class="line">		print(&apos;step %d, training accuracy %g&apos; % (i, train_accuracy))</div><div class="line">	sess.run(train_step, feed_dict = &#123;x: batch[0], y: batch[1], keep_prob: 0.5&#125;)</div><div class="line"></div><div class="line">test_accuracy = sess.run(accuracy, feed_dict = &#123;x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0&#125;)</div><div class="line">print(&apos;test accuracy %g&apos; % test_accuracy)</div><div class="line">sess.close()</div></pre></td></tr></table></figure>
<p>参考：<br><a href="http://blog.csdn.net/u011974639/article/details/75363565#卷积神经网络简介" target="_blank" rel="external">http://blog.csdn.net/u011974639/article/details/75363565#卷积神经网络简介</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/MNIST/" rel="tag"># MNIST</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/10/17/经典卷积神经网络(AlexNet)/" rel="next" title="经典卷积神经网络（AlexNet）">
                <i class="fa fa-chevron-left"></i> 经典卷积神经网络（AlexNet）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/10/26/git的基本命令/" rel="prev" title="git的基本命令">
                git的基本命令 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Zejian" />
          <p class="site-author-name" itemprop="name">Zejian</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">25</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/lizejian" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络"><span class="nav-number">1.</span> <span class="nav-text">卷积神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络结构）"><span class="nav-number">2.</span> <span class="nav-text">卷积神经网络结构）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#输入层"><span class="nav-number">2.1.</span> <span class="nav-text">输入层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积层"><span class="nav-number">2.2.</span> <span class="nav-text">卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积"><span class="nav-number">2.2.1.</span> <span class="nav-text">卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#权值共享"><span class="nav-number">2.2.2.</span> <span class="nav-text">权值共享</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多卷积核"><span class="nav-number">2.2.3.</span> <span class="nav-text">多卷积核</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化层"><span class="nav-number">2.3.</span> <span class="nav-text">池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层"><span class="nav-number">2.3.1.</span> <span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出层"><span class="nav-number">2.3.2.</span> <span class="nav-text">输出层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TensorFlow部署CNN"><span class="nav-number">3.</span> <span class="nav-text">TensorFlow部署CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积-1"><span class="nav-number">3.1.</span> <span class="nav-text">卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化"><span class="nav-number">3.2.</span> <span class="nav-text">池化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数"><span class="nav-number">3.3.</span> <span class="nav-text">激活函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-应用-MNIST"><span class="nav-number">4.</span> <span class="nav-text">CNN 应用 MNIST</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zejian</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
